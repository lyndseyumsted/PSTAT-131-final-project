---
title: "XGBoost Classification"
author: "Lyndsey Umsted"
date: "2022-11-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading neccessary libraries:
```{r}
library(tidyverse)
library(dplyr)
library(glmnet)
library(xgboost)
library(ranger)
library(lsr)
library(corrr)
library(tidyr)
library(car)
library(moments)
library(ggpubr)
library(BBmisc)
library(rsample)
library(recipes)
library(randomForest)
library(parsnip)
library(workflows)
library(tune)
library(dials)
library(yardstick)
require(xgboost)
require(data.table)
require(Matrix)
library(caret)
library(data.table)
library(mlr3)
library(class)
library(ParamHelpers)
```

Splitting into training and testing
```{r}
setwd("C:/Users/18586/Desktop/PSTAT 131/PSTAT-131-final-project/models")
load("pandemic_cum.rda")

set.seed(2002)

pandemic_cum <- pandemic_cum %>%
  select(-c("prop", "confirmed_cases", "population"))

pandemic_cum_split <- initial_split(pandemic_cum, prop = 0.80, strata = risk)

pandemic_cum_train <- training(pandemic_cum_split)
pandemic_cum_test <- testing(pandemic_cum_split)

pandemic_folds <- vfold_cv(pandemic_cum_train[,-1], v = 10, strata = risk)  # 10-fold CV

pandemic_cum_rec <- recipe(risk ~ ., data = pandemic_cum_train[,-1]) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_predictors()) 

```

```{r}
set.seed(2002)
xgb_spec <-
  boost_tree(
    mtry = tune(),
    trees = tune(),
    min_n = tune(),
    learn_rate = tune()
  ) %>%
  set_engine('xgboost') %>%
  set_mode('classification')

# add it to a workflow
xgb_wflow <-
  workflow() %>%
  add_recipe(pandemic_cum_rec) %>%
  add_model(xgb_spec)


xgb_grid <- grid_regular(mtry(range = c(2, 21)), trees(range = c(6,10)), min_n(range = c(3, 5)), learn_rate(range = c(0.0001,0.1)), levels = 8)

set.seed(2002)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
  tune_grid(
    xgb_wflow,
    resamples = pandemic_folds,
    grid = xgb_grid,
    metrics = metric_set(roc_auc)
  )
```

```{r}
xgb_plot <- autoplot(xgb_res)
xgb_plot
save(xgb_plot, file = "xgb_plot.rda")
```

```{r}
library(vip)
best <- select_best(xgb_res)

xgb_final <- finalize_workflow(xgb_wflow, best)

xgb_final_fit <- fit(xgb_final, data = pandemic_cum_train[,-1])

save(xgb_final_fit, file = "xgb_final_fit.rda")

xgb_final_fit %>%
  extract_fit_parsnip() %>%
  vip()
```

accuracy on testing:
```{r}
augment(xgb_final_fit, new_data = pandemic_cum_test[,-1]) %>%
  accuracy(truth = risk, estimate = .pred_class)
```


accuracy on training:
```{r}
xgb_acc <- augment(xgb_final_fit, new_data = pandemic_cum_train[,-1]) %>%
  accuracy(truth = risk, estimate = .pred_class)
xgb_acc
```



AUC:
```{r}
roc <- augment(xgb_final_fit, pandemic_cum_train[,-1])

xgb_auc <- roc %>%
  roc_auc(risk, c(.pred_low, .pred_moderate, .pred_high))

xgb_auc
```

ROC Curves:
```{r}
xgb_roc <- roc %>%
  roc_curve(risk, c(.pred_low, .pred_moderate, .pred_high)) %>%
  autoplot()

xgb_roc
```


Confusion Matrix:
```{r}
xgb_conf_matx <- augment(xgb_final_fit, new_data = pandemic_cum_test[,-1]) %>%
  conf_mat(truth = risk, estimate = .pred_class) %>%
  autoplot(type = "heatmap")

xgb_conf_matx

save(xgb_conf_matx, file = "xgb_conf_matx.rda")
```


Testing Performance:
```{r}
xgb_acc_test <- augment(xgb_final_fit, new_data = pandemic_cum_test[,-1]) %>%
  accuracy(truth = risk, estimate = .pred_class)
xgb_acc_test


roc <- augment(xgb_final_fit, pandemic_cum_test[,-1])

xgb_auc_test <- roc %>%
  roc_auc(risk, c(.pred_low, .pred_moderate, .pred_high))

xgb_auc_test

xgb_roc_test <- roc %>%
  roc_curve(risk, c(.pred_low, .pred_moderate, .pred_high)) %>%
  autoplot()

xgb_roc_test

save(xgb_acc_test, file = "xgb_acc_test.rda")
save(xgb_auc_test, file = "xgb_auc_test.rda")
```




Saving Performance:
```{r}
save(xgb_acc, file = "xgb_acc.rda")
save(xgb_roc, file = "xgb_roc.rda")
save(xgb_auc, file = "xgb_auc.rda")
```


